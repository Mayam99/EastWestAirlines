# -*- coding: utf-8 -*-
"""EastWestAirlines-K-means.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QSFOUXP48y7C_7ipJ6-ggaH0jku_hyzK

#About Dataset
###The file EastWestAirlines contains information on passengers who belong to an airlineâ€™s frequent flier program. For each passenger, the data include information on their mileage history and on different ways they accrued or spent miles in the last year. The goal is to try to identify clusters of passengers that have similar characteristics for the purpose of targeting different segments for different types of mileage offers

#Dataset Features:


* ID: Unique identifier for each customer.
* Balance: The amount of money in the customer's account.
* Qual_miles: Number of miles the customer qualifies for in the airline's        frequent flyer program.
* cc1_miles: Number of miles earned with the first airline credit card.
* cc2_miles: Number of miles earned with the second airline credit card.
* cc3_miles: Number of miles earned with the third airline credit card.
* Bonus_miles: Number of miles earned from non-flight activities.
* Bonus_trans: Number of transactions resulting in bonus miles.
* Flight_miles_12mo: Number of flight miles in the past 12 months.
* Flight_trans_12: Number of flight transactions in the past 12 months.
* Days_since_enroll: Number of days since the customer enrolled in the frequent flyer program.

#Importing Necessary Libraries
###We are required to importing the libraries so as to performing EDA. These include NumPy, Pandas, Matplotlib, and Seaborn.
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd # Pandas is a powerful library for data manipulation and analysis.
import numpy as np # NumPy is a powerful tool for numerical computations in Python.
import matplotlib.pyplot as plt  # Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python
import seaborn as sns # Seaborn is a statistical data visualization library based on Matplotlib
# %matplotlib inline

"""#Loading the Dataset
###The line df = pd.read_csv starts the process of reading a CSV file into a pandas DataFrame.
###This allows for easy data manipulation and analysis using pandas functionalities.

"""

df= pd.read_csv("EastWestAirlines.csv")

df.head() # Displays the first 5 rows of the Dataset

df.columns # Displays the names of the columns

df.shape # Displays the total count of the Rows and Columns of the dataset respectively.

df.describe(include = 'all')

df.info() #This function provides a concise summary of a DataFrame, giving a quick overview of its structure and the data it contains.

"""###The dataset consists of 12 numerical variables"""

df.isnull().sum() # Displays the total count of the null valuesin the particular columns.

"""###As we can check that there is no Null or Missing value in the data

## Normalization function
"""

from sklearn.preprocessing import StandardScaler #This line imports the StandardScaler class from the sklearn.preprocessing module in the scikit-learn library. StandardScaler is used to standardize the features of your dataset.
scaler = StandardScaler() #An instance of StandardScaler is created and stored in the variable scaler. This object will be used to compute the mean and standard deviation for each feature and then apply the scaling.
scaled_df_df = scaler.fit_transform(df.iloc[:,1:]) # df.iloc[:,1:] is used to select all the columns of the DataFrame df except the first one. The .iloc method is used for integer-location based indexing

scaled_df_df

for i in range(1,4):  #This code snippet creates a simple for loop that iterates over the numbers 1, 2, and 3. In each iteration, it prints the current value of the loop variable i.
  print(i)

from sklearn.cluster import KMeans
wcss = [] #An empty list wcss is initialized to store the Within-Cluster Sum of Squares (WCSS) for different values of k (number of clusters).
for i in range(1, 11): #This line sets up a for loop that iterates over the range of numbers from 1 to 10 inclusive. Each number represents the number of clusters (n_clusters) for the k-means algorithm.
    kmeans = KMeans(n_clusters=i,random_state=0) #Inside the loop, a KMeans object is created with n_clusters set to the current value of i and random_state set to 0 for reproducibility. The random_state parameter ensures that the results are the same each time the code is run.
    kmeans.fit(scaled_df_df) #The fit method is called on the KMeans object to fit the k-means algorithm to the scaled_df_df data. This step performs the clustering.
    wcss.append(kmeans.inertia_) #The inertia_ attribute of the fitted KMeans object is accessed, which gives the WCSS for the current number of clusters.
    if i > 2:
      break #This if statement checks if the current value of i is greater than 2. If it is, the break statement is executed, which exits the loop. This means the loop will only run for i values 1, 2, and 3, and then it will stop.

wcss

wcss = [] # Initializes an empty list wcss to store WCSS values.
for i in range(1, 11): #Sets up a loop to iterate over cluster numbers from 1 to 10.
    kmeans = KMeans(n_clusters=i,random_state=0) #Creates a KMeans object with the current number of clusters.
    kmeans.fit(scaled_df_df) #Fits the k-means algorithm to the scaled data.
    wcss.append(kmeans.inertia_) #Appends the WCSS (inertia) for the current clustering to the wcss list.

plt.plot(range(1, 11), wcss) #This line plots the number of clusters (from 1 to 10) on the x-axis and the corresponding WCSS values on the y-axis.
plt.title('Elbow Method') #This sets the title of the plot to "Elbow Method".
plt.xlabel('Number of clusters') #This labels the x-axis as "Number of clusters".
plt.ylabel('WCSS') #This labels the y-axis as "WCSS".
plt.show() #This displays the plot.

#Build Cluster algorithm
from sklearn.cluster import KMeans
clusters_new = KMeans(6, random_state=42) #Creates a KMeans clustering model with 6 clusters and a specified random state for reproducibility.
clusters_new.fit(scaled_df_df) #Fits the KMeans model to the scaled data (scaled_df_df), thereby partitioning the data into 6 clusters.

clusters_new.labels_ #provides a straightforward way to access the cluster assignments for each data point in your dataset after the clustering model has been trained

#Assign clusters to the data set
df['clusterid_new'] = clusters_new.labels_ # Adds'clusterid_new' as a new column to the DataFrame df using clusters_new.labels_ allows us to integrate the cluster assignments directly into original data structure.

#these are standardized values.
clusters_new.cluster_centers_ #It is a crucial attribute in KMeans clustering that allows us to access the centroids of the clusters identified in the dataset.

df.head() #checking for the new column that is added

df[df['clusterid_new']==0] #It returns a new DataFrame containing only the rows where 'clusterid_new' has the value 0

"""##df[df['clusterid_new']==0] is a pandas DataFrame operation that filters rows based on the condition 'clusterid_new' == 0.
##It returns a new DataFrame containing only the rows where 'clusterid_new' has the value 0, allowing us to analyze or manipulate data specific to that cluster within the DataFrame df.
"""

df[df['clusterid_new']==1] #It returns a new DataFrame containing only the rows where 'clusterid_new' has the value 1

df[df['clusterid_new']==2] #It returns a new DataFrame containing only the rows where 'clusterid_new' has the value 2

df[df['clusterid_new']==3] #It returns a new DataFrame containing only the rows where 'clusterid_new' has the value 3

df[df['clusterid_new']==4] #It returns a new DataFrame containing only the rows where 'clusterid_new' has the value 4

df[df['clusterid_new']==5] #It returns a new DataFrame containing only the rows where 'clusterid_new' has the value 5

